%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% a0poster Landscape Poster
% LaTeX Template
% Version 1.0 (22/06/13)
%
% The a0poster class was created by:
% Gerlinde Kettl and Matthias Weiser (tex@kettl.de)
% 
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a0,landscape]{a0poster}

\usepackage{multicol} % This is so we can have multiple columns of text side-by-side
\columnsep=100pt % This is the amount of white space between the columns in the poster
\columnseprule=3pt % This is the thickness of the black line between the columns in the poster

\usepackage[svgnames]{xcolor} % Specify colors by their 'svgnames', for a full list of all colors available see here: http://www.latextemplates.com/svgnames-colors

\usepackage{times} % Use the times font
%\usepackage{palatino} % Uncomment to use the Palatino font

\usepackage{graphicx} % Required for including images
\graphicspath{{figures/}} % Location of the graphics files
\usepackage{booktabs} % Top and bottom rules for table
\usepackage[font=small,labelfont=bf]{caption} % Required for specifying captions to tables and figures
\usepackage{amsfonts, amsmath, amsthm, amssymb} % For math fonts, symbols and environments
\usepackage{wrapfig} % Allows wrapping text around tables and figures

%------------------------
% xelatex
\usepackage{fontspec}
\usepackage{xunicode}
\usepackage{xltxtra}

% languages
\usepackage{fixlatvian}
\usepackage{polyglossia}
\setdefaultlanguage{latvian}
%\setotherlanguages{english,russian}

% bibliography
%\usepackage{csquotes}
\usepackage[
    backend=biber,
    style=numeric-comp,
    sorting=none,
    natbib=true,
    url=false,
    doi=true%,
    %eprint=false
]{biblatex}
\addbibresource{bibliography.bib}

%pseidokodam
\usepackage[boxed,linesnumbered]{algorithm2e}
\SetAlgorithmName{Algoritms}{}{Algoritmu saraksts}

\usepackage{float}


% ------------New commands------------
\newcommand{\keywordname}{Atslēgas vārdi:}
\newcommand{\keywords}[1]{\par\addvspace\baselineskip\noindent\keywordname\enspace\ignorespaces#1}

% Theorems
\numberwithin{equation}{section}
\renewcommand{\theequation}{\thesection\arabic{equation}}
\theoremstyle{definition}
\newtheorem{definicija}{Defin\={\i}cija}%
\newtheorem{pienemums}{Pie\c{n}\={e}mums}%
\newtheorem{piemers}{Piem\={e}rs}%
\theoremstyle{plain}
\newtheorem{teorema}{Teor\={e}ma}%
\newtheorem{apgalvojums}[teorema]{Apgalvojums}%
\newtheorem{lemma}[teorema]{Lemma}%
\newtheorem{sekas}[teorema]{Sekas}%
\newtheorem{piezime}[teorema]{Piez\={\i}me}
\renewcommand\proofname{Pier\={a}d\={\i}jums}
\newenvironment{pieradijums}{\begin{proof}}{\end{proof}}

\begin{document}

%----------------------------------------------------------------------------------------
%	POSTER HEADER 
%----------------------------------------------------------------------------------------

% The header is divided into three boxes:
% The first is 55% wide and houses the title, subtitle, names and university/organization
% The second is 25% wide and houses contact information
% The third is 19% wide and houses a logo for your university/organization or a photo of you
% The widths of these boxes can be easily edited to accommodate your content as you see fit

\begin{minipage}[b]{0.55\linewidth}
\veryHuge \color{NavyBlue} \textbf{Neironu tīkli un nepārtrauktas darbību telpas Markova izvēles procesi} \color{Black}\\ % Title
\Huge\textit{Maģistra kursa darbs}\\[1cm] % Subtitle
\huge \textbf{Rihards Krišlauks}\\ % Author(s)
\huge Latvijas Universitātes Datorikas fakultāte\\ % University/organization
\end{minipage}
%
\begin{minipage}[b]{0.25\linewidth}
\color{DarkSlateGray}\Large \textbf{Contact Information:}\\
Department Name\\ % Address
University Name\\
123 Broadway, State, Country\\\\
Phone: +1 (000) 111 1111\\ % Phone number
Email: \texttt{john@LaTeXTemplates.com}\\ % Email address
\end{minipage}
%
\begin{minipage}[b]{0.19\linewidth}
\includegraphics[width=20cm]{lu-logo-full.png} % Logo or a photo of you, adjust its dimensions here
\end{minipage}

\vspace{1cm} % A bit of extra whitespace between the header and poster content

%----------------------------------------------------------------------------------------

\begin{multicols}{4} % This is how many columns your poster will be broken into, a poster with many figures may benefit from less columns whereas a text-heavy poster benefits from more

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\color{Navy} % Navy color for the abstract

\begin{abstract}

Neironu tīklu lietojums praksē un literatūrā ir parādījis to pozitīvās īpašības, kā robustumu, spēju vispārināt un pielietojuma iespēju daudzveidību.
Darbā tiek pētīts neironu tīklu lietojums stimulētās mācīšanās paradigmā, ar mērķi pētīt iespējas to labās īpašības pārnest uz šo nozari, īpašu uzmanību pievēršot tieši to pielietojumam nepārtrauktu darbības telpu Markova izvēles procesos.
Autors iztirzā literatūrā parādīto klasisko pieeju un algoritmu atsevišķu komponenšu sniegumu nozīmīgākajos aspektos, kas saistīti ar to lietojumu nepārtrauktās darbību telpās.
Izpētes gaitā tiek nonākts līdz continuous action-critic learning automaton (CACLA) algoritmam, kas pārvar problēmas, ar ko saskaras citi apskatītie algoritmi un pieejas gan lietojamībā nepārtrauktās darbību telpās, gan savietojamībā ar neironu tīkliem, kā arī tiek secināts, ka tā darbībā ir vairākas citas pozitīvas īpašības.
%Darbs tiek noslēgts ar diskusiju par 

\keywords{stimulētā mācīšanās; neironu tīkli; Markova izvēles procesi; nepārtrauktas telpas.}

\end{abstract}

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\color{SaddleBrown} % SaddleBrown color for the introduction

\section*{Ievads}

Salīdzinot mašīnmācīšanās disciplīnas, stimulētā mācīšanās uz pārējo fona izceļas.
Tā stāv ļoti tuvu intuitīvajai izpratnei, par to, kas vispār ir mācīšanās tādā nozīmē, kā to dara dzīvnieki vai cilvēks.
Tās pamatā ir aģenta mijiedarbība ar apkārtējo vidi, lai patstāvīgi iemācītos tajā darboties, atbilstoši kādai izpratnei par optimālumu.
Kā jau matemātiskā disciplīnā tajā apskatāmās situācijas tiek formalizētas, un parasti tas tiek darīts ar Markova izvēles procesu palīdzību.
Tas ļauj stimulētās mācīšanās paradigmā formulēt ļoti plašu problēmu loku, sākot ar, piemēram, orientēšanos labirintā, līdz autonomai lidaparāta kontrolei.

Uzdevumu risināšana nepārtrauktās darbību telpās ir plaši pētīta, un to var veikt samērā sekmīgi.
Tomēr citāda situācija paveras nepārtrauktu darbības telpu gadījumā.
Šāda tipa uzdevumu risināšana ir mazāk pētīta, un plaši lietotās nepārtrauktu stāvokļu telpu pieejas šeit nav tiešā veidā izmantojamas.

No otras puses, literatūrā un praksē ir sastopams daudz piemēru, kas izceļ neironu tīklus kā universālu līdzekli dažāda tipa problēmu risināšanā.
Tiek demonstrētas to pozitīvās īpašības, kā robustums, spēja vispārināt un pielietojuma iespēju daudzveidība.
Ir zināms, ka neironu tīkli var kalpot kā universāls nepārtrauktu funkciju aproksimācijas līdzeklis.
Tas liek domāt, ka neironu tīkli ir dabīgā veidā izmantojami stimulētās mācīšanās uzdevumos aģenta darbību izvēles mehānisma reprezentācijai.
To var intuitīvi pamatot ar neironu tīklu spēju atrast sakarības datos -- virspusēji nav redzami ierobežojumi, lai šī īpašība nebūtu pārnesama arī stimulētās mācīšanās uzdevumos, sakarību meklēšanai aģenta kontroles stratēģijā.
Turklāt, ir pamats domāt, ka rezultātā iegūtā algoritma uzbūve būtu gana vispārīga, lai to kā universālu līdzekli pielietotu plašam problēmu lokam.

%----------------------------------------------------------------------------------------
%	OBJECTIVES
%----------------------------------------------------------------------------------------

\color{DarkSlateGray} % DarkSlateGray color for the rest of the content

\section*{Galvenie mērķi}

Par darba mērķi tiek izvirzīts izvērtēt iespējas risināt stimulētās mācīšanās uzdevumus nepārtrauktās darbības telpās, izmantojot neironu tīklus kā līdzekli stratēģijas reprezentēšanai.
Meklētas tiek vispārīgas pieejas, problēmas risināšanai, kas ļautu nonākt pie universāla un viegli pielietojama algoritma stimulētās mācīšanās uzdevumu risināšanai nepārtrauktās darbību telpās.

%----------------------------------------------------------------------------------------
%	MATERIALS AND METHODS
%----------------------------------------------------------------------------------------

\section*{Markova izvēles procesi}

Markova izvēles procesi (angliski Markov decision processes, turpmāk tekstā - MDP) formalizē un ļauj modelēt izvēles veikšanas procesu apstākļos, kur darbības rezultāts ir atkarīgs tikai no sistēmas pašreizējā stāvokļa, bet ir daļēji nejaušs, t.i., izvēles veicējs procesu kontrolē tikai daļēji.
Mērķis ir kontrolēt sistēmu tā, lai tiktu maksimizēta kāda metrika, kas ir atkarīga no katrā solī veiktās darbības rezultāta.
Tiek uzskatīts, ka MDP ir ieviesti \autocite{Bel}.

\begin{definicija}
Par Markova izvēles procesu, jeb MDP, sauc kortežu $(S, A, T, R)$, kur:
\begin{itemize}
	\item $S \subseteq \mathbb{R}^{D_S}$, kur $D_S \in \mathbb{N}$, ir stāvokļu kopa, %TODO iespējams bezgalīga?
	\item $A \subseteq \mathbb{R}^{D_A}$, kur $D_A \in \mathbb{N}$, ir darbību kopa, %TODO iespējams bezgalīga?
	\item $T:S \times A \times S \rightarrow [0,1]$ ir pārejas funkcija, kur $T(s, a, s')$ norāda varbūtību, esot stāvoklī $s \in S$ veicot darbību $a \in A$, nonākt stāvoklī $s' \in S$,
	\item $R:S \times A \times S \rightarrow \mathbb{R}$ ir atalgojuma funkcija, $R(s, a, s')$ norāda atalgojumu, kas tiek saņemts, esot stāvoklī $s \in S$ veicot darbību $a \in A$ un pēc tam nonākot stāvoklī $s' \in S$.
\end{itemize}
Ja stāvokļu telpa ir nepārtraukta, $T(s, a, s')$ apzīmē varbūtību blīvuma funkciju, jeb
\[
	\int_{S'} T(s, a, s')ds' = P(s_{t+1} \in S' \mid s_t = s \land a_t = a),
\]
kas norāda varbūtību, ka stāvoklī $s \in S$, veicot darbību $a \in A$ pāreja beigsies stāvoklī, kas pieder apgabalam $S'$. %TODO jāpaskaidro _t un _{t+1}?
\end{definicija}
%------------------------------------------------

\subsection*{Modeļa aproksimācija}
Modeļa aproksimācijas pieejā tiek mēģināts tuvināti atrast dotās MDP nezināmos parametrus -- pāreju funkciju $T$ un atalgojuma funkciju $R$ --, lai no tām atvasinātu aproksimētās MDP optimālo kontroles shēmu.
Modeļa meklēšanā tiek pieņemts, ka kopas $S$ un $A$ ir zināmas.
Dziļākam ieskatam metodēs, kas tiek izmantotas modeļa aproksimēšanā, skatīt \autocite{nguyen2011model}.

\subsection*{Vērtību aproksimācija}
Vērtību aproksimācijas piegājienā tiek nevis mēģināts atrast trūkstošās pāreju un atalgojuma funkcijas, bet gan tiek uzreiz mēģināts tuvināti atrast funkcijas $V^*$ vai $Q^*$.
Kā redzams iepriekšējā sadaļā, vienādojumi \eqref{eq:1} un \eqref{eq:2} ļauj atrast $\pi^*$, ja $V^*$ vai $Q^*$ ir zināma.
Šīs kategorijas algoritmus iedala atkarībā no tā, vai tie ir spējīgi mācīties tiešsaistē, un vai algoritms ir on-policy vai off-policy tipa.

\subsection*{Stratēģijas aproksimācija}
Atšķirībā no vērtību aproksimācijas algoritmiem, stratēģijas aproksimācijas pieejas algoritmi optimālās stratēģijas tuvinājumu glabā tiešā veidā.
Parasti nav nekādu šķēršļu $\pi^*$ reprezentācijai izmantot kādu vispārīgu funkciju aproksimētāju. Tādā gadījumā algoritms glabā tā parametrus.
Šim nolūkam var tikt izmantots arī neironu tīkls.
Bez tuvinātas optimālās stratēģijas mēdz tikt glabāta arī $V^{\pi^*}$ vai $Q^{\pi^*}$ funkcija.
Algoritmus, kuros tiek tā darīts, mēdz saukt par actor-critic algoritmiem, ar vārdu critic atsaucoties uz algoritma daļu, kas vērtē spēles stāvokļa izdevību, jeb $V^{\pi^*}$ vai $Q^{\pi^*}$, un ar actor atsaucoties uz stratēģiju.
Pēc analoģijas, stratēģijas aproksimācijas algoritmus, kas neizmanto kādu no vērtību funkcijām, dēvē par actor-only algoritmie, savukārt vērtību aproksimācijas algoritmus -- par critic-only algoritmiem.
Stratēģijas aproksimācijas algoritmi tiks tuvāk apskatīti \ref{chap:stim} nodaļā.

%----------------------------------------------------------------------------------------
%	RESULTS 
%----------------------------------------------------------------------------------------

%\section*{Funkciju aproksimācija}

\section*{Neironu tīkli un nelineārā funkciju aproksimēšana}
Neironu tīkli pieder pie nelineārajiem funkciju aproksimētājiem.
Tie it veidoti uz līdzību pamata ar bioloģisko neironu tīkliem smadzenēs un parasti tiek formulēti kā savstarpēji savienotu "neironu" sistēma, kas dotus ieejas datus pārvērš izejas datos atbilstoši sistēmas neironu svariem.
Katru neironu raksturo svaru komplekts, kas ir koeficienti dotā neirona ieejas neironu vērtībām.
Neirons izejā dod ieejas neironu signālu un svaru lineāru kombināciju, kam pielietota kāda (parasti) nelineāra funkcija. To dēvē par aktivācijas funkciju.
Praksē bieži tiek lietota t.s. simgoid funkcija
\[
	f(x) = \frac{1}{1 + e^{-x}}.
\]
Izsakot to atkarībā no neirona svaru vektora $\Theta$, iegūst
\[
	f_\Theta(x) = \frac{1}{1 + e^{-\Theta^T x}},
\]
kur $D_\Theta = D_x$. Formāli neironu tīkls ir parasta parametrizējama funkcija, bet šāds skatījums ir intuitīvi vieglāk saprotams.

%\begin{figure}
%	\centering
%	\includegraphics{placeholder}
%	\caption{Neironu tīkla arhitektūras piemērs.}
%	\label{fig:nn}
%\end{figure}

\begin{center}\vspace{1cm}
\includegraphics[width=0.8\linewidth]{nn-arhitektura.pdf}
\captionof{figure}{\color{Green} Figure caption}
\end{center}\vspace{1cm}

\section*{Stimulētā mācīšanās}
\subsection*{Temporal difference soļi} \label{chap:td}
Temporal difference (TD) soļi tiek izmantoti stāvokļu vērtības funkcijas aproksimācijā.
Šis paņēmiens ir idejiski tuvās vērtības aproksimācijas metodēm, bet, kā vēlāk redzēsim, ir izmantojams arī actor-critic metodēs, lai iegūtu $V^*$ aproksimāciju.
Pastāv dažādas idejas variācijas, kas ir pamatā vairākiem vērtību aproksimācijas algoritmiem, kas tiek klasificēti zem TD learning vārda, bet pamatideja ir vienkārša.
TD soļiem tabulārajā formā stāvokļu vērtību funkcija tiek pielāgota, izmantojot vienādojumu
\[
	V_{t+1}(s_t) = V_t + \alpha_t(s_t) \delta_t,
\]
kur $\delta_t = r_{t} + \gamma V_t(s_{t + 1}) - V_t(s_t)$ un $\alpha_t(s_t) \in [0,1]$ ir soļa lieluma parametrs.
Nepārtrauktai stāvokļu vērtību funkcijai TD soļa pielietošana ir saistīta ar gradient ascent soļa veikšanu funkcijas parametriem.
Ja ir dota parametrizēta vērtību funkcija $V:S \times \Theta \rightarrow \mathbb{R}$, tad TD solis tiek veikts funkcijas parametriem atbilstoši vienādojumam
\[
	\theta_{t+1} = \theta_t + \alpha_t(s_t) \delta_t \nabla_\theta V_t(s_t).
\]

\subsubsection*{CACLA algoritms}
CACLA algoritma pamatā ir vienkārša ideja -- ja veiktā darbība paaugstina stāvokļa vērtības novērtējumu, tad šim stāvoklim ir derīgi pielāgot stratēģiju veiktās darbības virzienā, jo tā potenciāli var novest pie lielāka kopējā atalgojuma.
%Paralēli tam, algoritms katrā solī uzlabo savu stāvokļu vērtības novērtējumu.
%Laika gaitā stāvokļu vērtības novērtējums konverģē uz  Rezultātā algoritma stratēģija ar vien vairāk tuvojas optimālajai.
Algoritms glabā funkciju $V:S \times \Theta \rightarrow \mathbb{R}$ -- kritiķi -- un $Ac : S \times \Psi \rightarrow A$ -- aktieri. Sasaistot apzīmējumus ar ierastajiem -- $V$ tagad tiek parametrizēta ar kādu vektoru $\theta \in \Theta$, kas ļaus pielāgot funkcijas vērtības algoritma darbības laikā. Apzīmēsim $V_t(s_t) = V(s_t, \theta_t)$ un $Ac_t(s_t) = Ac(s_t, \psi_t)$.
Aktieris katrā solī dotajam stāvoklim $s_t$ sniedz darbību $Ac(s_t, \psi_t)$.
Lai nodrošinātu darbību telpas izpēti, nepieciešams, lai galā izmantotā darbība atšķiras no ieteiktās, jeb $a_t \neq Ac(s_t, \psi_t)$.
To var darīt, piemēram, ņemot $\pi(s_t, \psi_t)$ kā normālsadalījumu ar centru $Ac(s_t, \psi_t)$.
Kad ir iegūta veicamā darbība $a_t$, novēro atalgojumu $r_t$ un veic standarta TD soli vērtību funkcijai, kā tas aprakstīts sadaļā \ref{chap:td}
\[
	V_{t+1}(s_t) \xleftarrow{\alpha_t(s_t)} r_t + \gamma V_t(s_{t + 1}).
\]
Ja $a_t$ veikšana ir palielinājusi $s_t$ vērtības novērtējumu, t.i., ja $V_{t+1}(s_t) > V_t(s_t)$, tad pielāgo aktieri darbības $a_t$ virzienā
\[
	Ac_{t+1}(s_t) \xleftarrow{\beta_t(s_t)} a_t.
\]


%\begin{spacing}{1}
\begin{center}\vspace{1cm}
\begin{algorithm}
%\caption{CACLA pseidokods}\label{alg:cacla}
inicializē $\theta_0, \psi_0, s_0$ \\
\For{$t \in \{0,1,2,\ldots\}$}{
	ņem $a_t$ ar izkliedi ap $Ac_t(s_t)$ \\
	veic $a_t$, novēro $r_t, s_{t+1}$ \\
	\eIf{$s_{t+1}$ ir gala stāvoklis}{
		$V_{t+1}(s_t) \xleftarrow{\alpha_t(s_t)} r_t$ \\
		ņem jaunu $s_{t+1}$ ($s_{t+1}$ ir sākumstāvoklis nākamajā trenēšanas epizodē)
	}{
		$V_{t+1}(s_t) \xleftarrow{\alpha_t(s_t)} r_t + \gamma V_t(s_{t + 1})$
	}
	\If{$V_{t+1}(s_t) > V_t(s_t)$}{
		$Ac_{t+1}(s_t) \xleftarrow{\beta_t(s_t)} a_t$
	}
}
\end{algorithm}
\end{center}
%\end{spacing}
%----------------------------------------------------------------------------------------
%	CONCLUSIONS
%----------------------------------------------------------------------------------------

\color{SaddleBrown} % SaddleBrown color for the conclusions to make them stand out

\section*{Secinājumi}

Modeļa aproksimācijas metodēs un plaši izmantotās vērtību aproksimācijas metodēs problēmas, kas saistās ar to pielietojumu nepārtrauktām darbību telpām nav vienkāršā veidā risināmas ar neironu tīkliem.
Tam traucē fakts, ka šeit stratēģija tiek atvasināta no vērtību funkcijas.
Tas arī saistās ar nepieciešamību diskretizēt darbību telpu.
Darbā netiek tuvāk pētīts, cik pārvarama ir šī problēma, bet tā vietā risinājums tiek meklēts alternatīvā pieejā, ko sniedz stratēģijas aproksimācijas metodes.
Stratēģiju glabājot tiešā veidā, paveras iespējas šo lomu uzticēt neironu tīklam.
Tomēr, kā nākas secināt, daļā metožu tīkla parametru pielāgošana, jeb tīkla trenēšana, it diezgan sarežģīta.
Actor-only metodēs nākas parametru pielāgošanu sarežģītā veidā sasaistīt ar atalgojuma funkcijas novērtējumiem, izmantojot Monte Carlo metodes.
Alternatīvu piedāvā actor-critic pieeja, kur tiešā veidā tiek glabāta gan stāvokļu vērtības funkcijas aproksimācija gan stratēģijas aproksimācija.
Šīs īpašības noved iespējas pie stratēģijas parametrus pielāgot, ņemot vērā kļūdu tās paredzēto darbību telpā, katras darbības labumu vērtējot ar izmaiņām, ko tās sniegtais atalgojums dod stāvokļa vērtības novērtējumam.
Šīs idejas ir apvienotas CACLA, jeb continuous actor-critic learning automaton, algoritmā.
Autora prāt algoritma dizains elegantā un vienkārša veidā iekļauj risinājumus visām iepriekš minētajām problēmām.
Turklāt ir empīriski parādītas priekšrocības, kas tam piemīt mācīšanās ātruma ziņā salīdzinot ar plaši izmantotajiem klasisko pieeju algoritmiem, kā arī algoritmam piemīt vairākas citas pozitīvas īpašības, kas izpaužas nestandarta uzdevumu uzstādījumos, kā, piemēram, darbinot CACLA diskrētā darbību telpā, pēc laika samazinot pieejamo darbību skaitu.

%Noslēgumā var secināt, ka s..
Rezultātā sākotnējā intuīcija par neironu tīklu lietderību stimulētas mācīšanās uzdevumos ar nepārtrauktām darbību telpām ir bijusi derīga.
Analizējot izplatītākās stimulētās mācīšanās pieejas, ir izdevies nonākt pie CACLA algoritma, kas dabīgā veidā risina problēmas, kas plašāk pazīstamajiem algoritmiem liedz tikt pielāgotiem nepārtrauktām darbību telpām, kā arī dara to ar neironu tīklu palīdzību.
Tas ļauj teikt, ka darba mērķis ir sasniegts.

\color{DarkSlateGray} % Set the color back to DarkSlateGray for the rest of the content

%----------------------------------------------------------------------------------------
%	FORTHCOMING RESEARCH
%----------------------------------------------------------------------------------------

\section*{Turpmākie pētījumi}

Kopumā ir daudz jaunu pieeju, kas būtu aizgūstamas no, tā teikt, vairāk klasiskās mašīnmācīšanās, un kam varētu rast pielietojumu stimulētās mācīšanās paradigmā.
Interesi raisa iespējas tās mēģināt savietot ar šajā darbā pētīto CACLA algoritmu, cerot, ka ieguvumi, ko sniedz tā izmantošana, ļautu, piemēram, sekmīgāk adaptēt dziļos neironu tīklus stratēģijas aproksimācijai.
Šī ir potenciāla tēma nākamajiem pētījumiem.

 %----------------------------------------------------------------------------------------
%	REFERENCES
%----------------------------------------------------------------------------------------

%\nocite{*} % Print all references regardless of whether they were cited in the poster or not
%\bibliographystyle{plain} % Plain referencing style
%\bibliography{sample} % Use the example bibliography file sample.bib

\printbibliography

%----------------------------------------------------------------------------------------
%	ACKNOWLEDGEMENTS
%----------------------------------------------------------------------------------------

%\section*{Acknowledgements}

%Etiam fermentum, arcu ut gravida fringilla, dolor arcu laoreet justo, ut imperdiet urna arcu a arcu. Donec nec ante a dui tempus consectetur. Cras nisi turpis, dapibus sit amet mattis sed, laoreet.

%----------------------------------------------------------------------------------------

\end{multicols}
\end{document}