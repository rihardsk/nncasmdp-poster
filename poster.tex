%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% a0poster Landscape Poster
% LaTeX Template
% Version 1.0 (22/06/13)
%
% The a0poster class was created by:
% Gerlinde Kettl and Matthias Weiser (tex@kettl.de)
% 
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[a0,landscape]{a0poster}

\usepackage{multicol} % This is so we can have multiple columns of text side-by-side
\columnsep=100pt % This is the amount of white space between the columns in the poster
\columnseprule=3pt % This is the thickness of the black line between the columns in the poster

\usepackage[svgnames]{xcolor} % Specify colors by their 'svgnames', for a full list of all colors available see here: http://www.latextemplates.com/svgnames-colors

\usepackage{times} % Use the times font
%\usepackage{palatino} % Uncomment to use the Palatino font

\usepackage{graphicx} % Required for including images
\graphicspath{{figures/}} % Location of the graphics files
\usepackage{booktabs} % Top and bottom rules for table
\usepackage[font=small,labelfont=bf]{caption} % Required for specifying captions to tables and figures
\usepackage{amsfonts, amsmath, amsthm, amssymb} % For math fonts, symbols and environments
\usepackage{wrapfig} % Allows wrapping text around tables and figures

%------------------------
% xelatex
\usepackage{fontspec}
\usepackage{xunicode}
\usepackage{xltxtra}

% languages
\usepackage{fixlatvian}
\usepackage{polyglossia}
\setdefaultlanguage{latvian}
%\setotherlanguages{english,russian}


%pseidokodam
\usepackage[boxed,linesnumbered]{algorithm2e}
\SetAlgorithmName{Algoritms}{}{Algoritmu saraksts}

\usepackage{float}


% ------------New commands------------
\newcommand{\keywordname}{Atslēgas vārdi:}
\newcommand{\keywords}[1]{\par\addvspace\baselineskip\noindent\keywordname\enspace\ignorespaces#1}

% Theorems
\numberwithin{equation}{section}
\renewcommand{\theequation}{\thesection\arabic{equation}}
\theoremstyle{definition}
\newtheorem{definicija}{Defin\={\i}cija}%
\newtheorem{pienemums}{Pie\c{n}\={e}mums}%
\newtheorem{piemers}{Piem\={e}rs}%
\theoremstyle{plain}
\newtheorem{teorema}{Teor\={e}ma}%
\newtheorem{apgalvojums}[teorema]{Apgalvojums}%
\newtheorem{lemma}[teorema]{Lemma}%
\newtheorem{sekas}[teorema]{Sekas}%
\newtheorem{piezime}[teorema]{Piez\={\i}me}
\renewcommand\proofname{Pier\={a}d\={\i}jums}
\newenvironment{pieradijums}{\begin{proof}}{\end{proof}}

\begin{document}

%----------------------------------------------------------------------------------------
%	POSTER HEADER 
%----------------------------------------------------------------------------------------

% The header is divided into three boxes:
% The first is 55% wide and houses the title, subtitle, names and university/organization
% The second is 25% wide and houses contact information
% The third is 19% wide and houses a logo for your university/organization or a photo of you
% The widths of these boxes can be easily edited to accommodate your content as you see fit

\begin{minipage}[b]{0.55\linewidth}
\veryHuge \color{NavyBlue} \textbf{Neironu tīkli un nepārtrauktas darbību telpas Markova izvēles procesi} \color{Black}\\ % Title
\Huge\textit{Maģistra kursa darbs}\\[1cm] % Subtitle
\huge \textbf{Rihards Krišlauks}\\ % Author(s)
\huge Latvijas Universitātes Datorikas fakultāte\\ % University/organization
\end{minipage}
%
\begin{minipage}[b]{0.25\linewidth}
\color{DarkSlateGray}\Large \textbf{Kontaktinformācija:}\\
E-pasts: \texttt{rihards.krislauks@gmail.com}\\ % Email address
\end{minipage}
%
\begin{minipage}[b]{0.19\linewidth}
\includegraphics[width=20cm]{lu-logo-full.png} % Logo or a photo of you, adjust its dimensions here
\end{minipage}

\vspace{1cm} % A bit of extra whitespace between the header and poster content

%----------------------------------------------------------------------------------------

\begin{multicols}{4} % This is how many columns your poster will be broken into, a poster with many figures may benefit from less columns whereas a text-heavy poster benefits from more

%----------------------------------------------------------------------------------------
%	ABSTRACT
%----------------------------------------------------------------------------------------

\color{Navy} % Navy color for the abstract

\begin{abstract}

Neironu tīklu lietojums praksē un literatūrā ir parādījis to pozitīvās īpašības, kā robustumu, spēju vispārināt un pielietojuma iespēju daudzveidību.
Darbā tiek pētīts neironu tīklu lietojums stimulētās mācīšanās paradigmā, ar mērķi pētīt iespējas to labās īpašības pārnest uz šo nozari, īpašu uzmanību pievēršot tieši to pielietojumam nepārtrauktu darbības telpu Markova izvēles procesos.
Autors iztirzā literatūrā parādīto klasisko pieeju un algoritmu atsevišķu komponenšu sniegumu nozīmīgākajos aspektos, kas saistīti ar to lietojumu nepārtrauktās darbību telpās.
Izpētes gaitā tiek nonākts līdz \textit{continuous action-critic learning automaton} (CACLA) algoritmam, kas pārvar problēmas, ar ko saskaras citi apskatītie algoritmi un pieejas gan lietojamībā nepārtrauktās darbību telpās, gan savietojamībā ar neironu tīkliem, kā arī tiek secināts, ka tā darbībā ir vairākas citas pozitīvas īpašības.
%Darbs tiek noslēgts ar diskusiju par 

\end{abstract}

%----------------------------------------------------------------------------------------
%	INTRODUCTION
%----------------------------------------------------------------------------------------

\color{SaddleBrown} % SaddleBrown color for the introduction

\section*{Ievads}

Salīdzinot mašīnmācīšanās disciplīnas, stimulētā mācīšanās (SM) uz pārējo fona izceļas.
Tā stāv ļoti tuvu intuitīvajai izpratnei, par to, kas vispār ir mācīšanās tādā nozīmē, kā to dara dzīvnieki vai cilvēks.
Tās pamatā ir aģenta mijiedarbība ar apkārtējo vidi, lai patstāvīgi iemācītos tajā darboties, atbilstoši kādai izpratnei par optimālumu.
SM paradigmā apskatāmās situācijas parasti tiek formalizētas ar Markova izvēles procesu palīdzību.
Tas ļauj stimulētās mācīšanās paradigmā apskatīt ļoti plašu problēmu loku, sākot ar, piemēram, orientēšanos labirintā, līdz autonomai lidaparāta kontrolei.

Uzdevumu risināšana nepārtrauktās stāvokļu telpās ir plaši pētīta, un to var veikt samērā sekmīgi.
Tomēr citāda situācija paveras nepārtrauktu darbības telpu gadījumā.
Šāda tipa uzdevumu risināšana ir mazāk pētīta, un plaši lietotās nepārtrauktu stāvokļu telpu pieejas šeit nav tiešā veidā izmantojamas.

No otras puses, literatūrā un praksē ir sastopams daudz piemēru, kas izceļ neironu tīklus kā universālu līdzekli dažāda tipa problēmu risināšanā.
Tiek demonstrētas to pozitīvās īpašības, kā robustums, spēja vispārināt un pielietojuma iespēju daudzveidība.
Ir zināms, ka neironu tīkli var kalpot kā universāls nepārtrauktu funkciju aproksimācijas līdzeklis.
Tas liek domāt, ka neironu tīkli ir dabīgā veidā izmantojami stimulētās mācīšanās uzdevumos aģenta darbību izvēles mehānisma reprezentācijai.


%----------------------------------------------------------------------------------------
%	OBJECTIVES
%----------------------------------------------------------------------------------------

\color{DarkSlateGray} % DarkSlateGray color for the rest of the content

\section*{Mērķi}
\begin{enumerate}
	\item Izvērtēt iespējas izmantot neironu tīklus SM stratēģijas reprezentēšanai nepārtrauktās darbības telpās.
	\item Izvērtēt idejas pamatotumu.
	\item Dot priekšroku vispārīgām pieejām problēmas risināšanai, kas ļautu nonākt pie universāla un viegli pielietojama algoritma
\end{enumerate}

%----------------------------------------------------------------------------------------
%	MATERIALS AND METHODS
%----------------------------------------------------------------------------------------

\section*{Markova izvēles procesi}

Markova izvēles procesi (angliski Markov decision processes, turpmāk - MDP) formalizē un ļauj modelēt izvēles veikšanas procesu apstākļos, kur darbības rezultāts ir atkarīgs tikai no sistēmas pašreizējā stāvokļa, bet ir daļēji nejaušs, t.i., izvēles veicējs procesu kontrolē tikai daļēji.
Mērķis ir kontrolēt sistēmu tā, lai tiktu maksimizēta kāda metrika, kas ir atkarīga no katrā solī veiktās darbības rezultāta.

\begin{definicija}
Par Markova izvēles procesu, jeb MDP, sauc kortežu $(S, A, T, R)$, kur:
\begin{itemize}
	\item $S \subseteq \mathbb{R}^{D_S}$, kur $D_S \in \mathbb{N}$, ir stāvokļu kopa, %TODO iespējams bezgalīga?
	\item $A \subseteq \mathbb{R}^{D_A}$, kur $D_A \in \mathbb{N}$, ir darbību kopa, %TODO iespējams bezgalīga?
	\item $T:S \times A \times S \rightarrow [0,1]$ ir pārejas funkcija, kur $T(s, a, s')$ norāda varbūtību, esot stāvoklī $s \in S$ veicot darbību $a \in A$, nonākt stāvoklī $s' \in S$,
	\item $R:S \times A \times S \rightarrow \mathbb{R}$ ir atalgojuma funkcija, $R(s, a, s')$ norāda atalgojumu, kas tiek saņemts, esot stāvoklī $s \in S$ veicot darbību $a \in A$ un pēc tam nonākot stāvoklī $s' \in S$.
\end{itemize}
Ja stāvokļu telpa ir nepārtraukta, $T(s, a, s')$ apzīmē varbūtību blīvuma funkciju, jeb
\[
	\int_{S'} T(s, a, s')ds' = P(s_{t+1} \in S' \mid s_t = s \land a_t = a).
\]
\end{definicija}

Ievieš arī funkciju $\pi: S \times A \rightarrow [0, 1]$, kas apzīmē stratēģiju, jeb kontroles shēmu:
\[
	\pi(s, a) = P(a_t = a \mid s_t = s).
\]
Uzdevums ir atrast tādu stratēģiju, lai maksimizētu lielumu
\[
	E\left[\sum_{t=0}^{\infty}\gamma^t r_t\right].
\]
%------------------------------------------------

\subsection*{Modeļa aproksimācija}
Modeļa aproksimācijas pieejā tiek mēģināts tuvināti atrast dotās MDP nezināmos parametrus -- pāreju funkciju $T$ un atalgojuma funkciju $R$ --, lai no tām atvasinātu aproksimētās MDP optimālo kontroles shēmu.
Kad modelis ir zināms, stratēģijas iegūšana tiek veikta ar metodēm, kas tuvākas dinamiskajai programmēšanai.

\subsection*{Vērtību aproksimācija}
Vērtību aproksimācijas piegājienā tiek nevis mēģināts atrast trūkstošās pāreju un atalgojuma funkcijas, bet gan tiek uzreiz mēģināts tuvināti atrast optimālās funkcijas $V^*$ vai $Q^*$.
Tas tālāk ļauj tuvināti atrast optimālo kontroles shēmu $\pi^*$ ir zināma.
Metodei pieder \textit{on-policy} algoritmi, kā, piemēram, \textit{temporal-difference} saimes algoritmi, kā arī \textit{off-policy} algoritmi, kā, piemēram, ir \textit{Q-learning} un tā varianti.

\subsection*{Stratēģijas aproksimācija}
Atšķirībā no vērtību aproksimācijas algoritmiem, stratēģijas aproksimācijas pieejas algoritmi optimālās stratēģijas tuvinājumu glabā tiešā veidā.
Parasti nav šķēršļu $\pi$ reprezentācijai izmantot kādu vispārīgu funkciju aproksimētāju kā neironu tīklu.
Bez tuvinātas optimālās stratēģijas mēdz tikt glabāta arī $V$ vai $Q$ aproksimācija.
Algoritmus, kuros tiek tā darīts, mēdz saukt par \textit{actor-critic} algoritmiem, ar vārdu \textit{critic} atsaucoties uz algoritma daļu, kas vērtē spēles stāvokļa izdevību, jeb $V^{\pi^*}$ vai $Q^{\pi^*}$, un ar \textit{actor} atsaucoties uz stratēģiju.

%----------------------------------------------------------------------------------------
%	RESULTS 
%----------------------------------------------------------------------------------------

%\section*{Funkciju aproksimācija}

\section*{Neironu tīkli un nelineārā funkciju aproksimēšana}
Neironu tīkli ir veidoti uz līdzību pamata ar bioloģiskajiem neironu tīkliem smadzenēs. Tā ir savstarpēji savienotu "neironu" sistēma, kas dotus ieejas datus pārvērš izejas datos.
Katru neironu raksturo svaru komplekts, kas ir koeficienti dotā neirona ieejas neironu vērtībām.
Neirons izejā dod ieejas neironu signālu un svaru lineāru kombināciju, kam pielietota kāda (parasti) nelineāra funkcija.
Praksē bieži tiek lietota t.s. \textit{simgoid} funkcija
\[
	f_\theta(x) = \frac{1}{1 + e^{-\theta^T x}}.
\]

%\begin{figure}
%	\centering
%	\includegraphics{placeholder}
%	\caption{Neironu tīkla arhitektūras piemērs.}
%	\label{fig:nn}
%\end{figure}

\begin{center}\vspace{1cm}
\includegraphics[width=0.8\linewidth]{nn-arhitektura.pdf}
\captionof{figure}{\color{Green} Figure caption}
\end{center}\vspace{1cm}

Neironu tīkls ar pietiekamu neironu skaitu ir izmantojams patvaļīgu funkciju aproksimēšanai.
Šī ir nozīmīga priekšrocība, salīdzinot ar, piemēram, lineārajiem funkciju aproksimājiem, un ir pamatā intuīcijai par neironu tīklu spēju uztvert sakarības MDP optimālajā kontroles stratēģijā.
Kā arī spēja aproksimēt nepārtrauktas funkcijas ir nepieciešama lai funkciju aproksimētājs būtu spējīgs darboties nepārtrauktās darbību telpās.

\section*{Stimulētā mācīšanās}
Stimuletas mācīšanās (SM, angliski -- \textit{reinforcement learning}) pārziņā ir situācijas, kurās uzdevums jārisina mijiedarbojoties ar apkārtējo vidi. 
Tā vietā, lai problēmu risinātu, dodot algoritmam sagatavotus ieejas datus ar norādītām labākajām darbībām, algoritms mācās no savas pieredzes, izmēģinot darbības un novērojot saņemto atalgojumu.
Vispārīgā gadījumā algoritmam ir patstāvīgi jāapgūst darbošanās sarežģītos problēmapgabalos, kur darbības labumu var izvērtēt tikai ilgtermiņā uz priekšu.


\subsection*{CACLA algoritms}
Algoritma pamatā ir vienkārša ideja -- ja veiktā darbība paaugstina stāvokļa vērtības novērtējumu, tad šim stāvoklim ir derīgi pielāgot stratēģiju veiktās darbības virzienā, jo tā potenciāli var novest pie lielāka kopējā atalgojuma.
Algoritms glabā funkciju $V:S \times \Theta \rightarrow \mathbb{R}$ -- kritiķi -- un $Ac : S \times \Psi \rightarrow A$ -- aktieri.
Aktieris katrā solī dotajam stāvoklim $s_t$ sniedz darbību $Ac(s_t, \psi_t)$.
Lai nodrošinātu darbību telpas izpēti, nepieciešams, lai galā izmantotā darbība atšķiras no ieteiktās, jeb $a_t \neq Ac(s_t, \psi_t)$, piemēram, ņemot $\pi(s_t, \psi_t)$ kā normālsadalījumu ar centru $Ac(s_t, \psi_t)$.
Kad ir iegūta veicamā darbība $a_t$, novēro atalgojumu $r_t$, un veic standarta TD soli, lai precizētu vērtību funkciju.
\[
	V_{t+1}(s_t) \xleftarrow{\alpha_t(s_t)} r_t + \gamma V_t(s_{t + 1}).
\]
Ja $a_t$ veikšana ir palielinājusi $s_t$ vērtības novērtējumu, t.i., ja $V_{t+1}(s_t) > V_t(s_t)$, tad pielāgo aktieri darbības $a_t$ virzienā
\[
	Ac_{t+1}(s_t) \xleftarrow{\beta_t(s_t)} a_t.
\]

\iffalse
%\begin{spacing}{1}
\begin{center}\vspace{1cm}
\begin{algorithm}
%\caption{CACLA pseidokods}\label{alg:cacla}
inicializē $\theta_0, \psi_0, s_0$ \\
\For{$t \in \{0,1,2,\ldots\}$}{
	ņem $a_t$ ar izkliedi ap $Ac_t(s_t)$ \\
	veic $a_t$, novēro $r_t, s_{t+1}$ \\
	\eIf{$s_{t+1}$ ir gala stāvoklis}{
		$V_{t+1}(s_t) \xleftarrow{\alpha_t(s_t)} r_t$ \\
		ņem jaunu $s_{t+1}$ ($s_{t+1}$ ir sākumstāvoklis nākamajā trenēšanas epizodē)
	}{
		$V_{t+1}(s_t) \xleftarrow{\alpha_t(s_t)} r_t + \gamma V_t(s_{t + 1})$
	}
	\If{$V_{t+1}(s_t) > V_t(s_t)$}{
		$Ac_{t+1}(s_t) \xleftarrow{\beta_t(s_t)} a_t$
	}
}
\end{algorithm}
\end{center}
%\end{spacing}
\fi
%----------------------------------------------------------------------------------------
%	CONCLUSIONS
%----------------------------------------------------------------------------------------

\color{SaddleBrown} % SaddleBrown color for the conclusions to make them stand out

\section*{Secinājumi}

\begin{itemize}
	\item Modeļa un plaši izmantotās vērtību aproksimācijas metodēs problēmas, kas saistās ar to pielietojumu nepārtrauktām darbību telpām, nav vienkāršā veidā risināmas ar neironu tīkliem.
	\item Stratēģiju glabājot tiešā veidā, paveras iespējas tās reprezentēšanu uzticēt neironu tīklam.
	\item \textit{Actor-only} metodēs nākas parametru pielāgošanu sarežģītā veidā sasaistīt ar atalgojuma funkcijas novērtējumiem, izmantojot \textit{Monte Carlo} metodes.
	\item Iespējams stratēģiju pielāgot, ņemot vērā kļūdu tās paredzēto darbību telpā, katras darbības labumu vērtējot ar izmaiņām, ko tās sniegtais atalgojums dod stāvokļa vērtības novērtējumam. Šī ideja ir pamatā CACLA.
	\item CACLA dizains eleganti ietver mērķos paustās idejas. Turklāt ir empīriski parādāmas priekšrocības mācīšanās ātrumā, salīdzinot to ar klasiskajiem algoritmiem.
	\item Intuīcija par neironu tīklu lietderību stimulētas mācīšanās uzdevumos ar nepārtrauktām darbību telpām ir bijusi pareiza, un darba mērķi ir sasniegti.
\end{itemize}

\color{DarkSlateGray} % Set the color back to DarkSlateGray for the rest of the content

%----------------------------------------------------------------------------------------
%	FORTHCOMING RESEARCH
%----------------------------------------------------------------------------------------

\section*{Turpmākiem pētījumiem}

Ir daudz jaunu pieeju, kas būtu aizgūstamas no, tā teikt, vairāk klasiskās mašīnmācīšanās, un kam varētu rast pielietojumu stimulētās mācīšanās paradigmā.
Interesi raisa iespējas tās mēģināt savietot ar šajā darbā pētīto CACLA algoritmu, cerot, ka ieguvumi, ko sniedz tā izmantošana, ļautu, piemēram, sekmīgāk adaptēt dziļos neironu tīklus stratēģijas aproksimācijai.
Šī ir potenciāla tēma nākamajiem pētījumiem.

 %----------------------------------------------------------------------------------------
%	REFERENCES
%----------------------------------------------------------------------------------------

%\nocite{*} % Print all references regardless of whether they were cited in the poster or not
%\bibliographystyle{plain} % Plain referencing style
%\bibliography{sample} % Use the example bibliography file sample.bib

%\printbibliography

%----------------------------------------------------------------------------------------
%	ACKNOWLEDGEMENTS
%----------------------------------------------------------------------------------------

%\section*{Acknowledgements}

%Etiam fermentum, arcu ut gravida fringilla, dolor arcu laoreet justo, ut imperdiet urna arcu a arcu. Donec nec ante a dui tempus consectetur. Cras nisi turpis, dapibus sit amet mattis sed, laoreet.

%----------------------------------------------------------------------------------------

\end{multicols}
\end{document}